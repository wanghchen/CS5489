{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** \\_\\_\\_\\_\\_\n",
    "\n",
    "**EID:** \\_\\_\\_\\_\\_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS5489 - Tutorial 10\n",
    "## Using Deep Features\n",
    "\n",
    "In this tutorial you will train a classifier to classify images with different types of cakes using deep features.\n",
    "\n",
    "First we need to initialize Python.  Run the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T02:51:21.815752Z",
     "start_time": "2023-01-24T02:51:21.361095Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib_inline   # setup output image format\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "import os\n",
    "import zipfile\n",
    "import fnmatch\n",
    "import skimage.io\n",
    "import skimage.transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, initialize Keras and Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T02:51:23.294214Z",
     "start_time": "2023-01-24T02:51:21.816880Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv2D, Flatten, Dropout, Input, BatchNormalization, \\\n",
    "                                    GlobalAveragePooling2D, Concatenate\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "import struct\n",
    "import sys\n",
    "print(\"Python:\", sys.version, \"Keras:\", keras.__version__, \"TF:\", tf.__version__)\n",
    "# use keras backend (K) to force channels-last ordering\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and Pre-processing\n",
    "Next we need to load the images.  Download `cakes.zip`, and put it in the same direcotry as this ipynb file.  **Do not unzip the file.** Then run the following cell to load the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T02:51:33.381820Z",
     "start_time": "2023-01-24T02:51:23.299371Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgdata = []\n",
    "classes = []\n",
    "\n",
    "# load the zip file\n",
    "filename = 'cakes.zip'\n",
    "zfile = zipfile.ZipFile(filename, 'r')\n",
    "\n",
    "for name in zfile.namelist():\n",
    "    # check file name matches\n",
    "    if fnmatch.fnmatch(name, \"cakes/*/*.jpg\"):\n",
    "        \n",
    "        # filename is : cakes/class/file.jpg\n",
    "        (fdir1, fname)  = os.path.split(name)  # get file name\n",
    "        (fdir2, fclass) = os.path.split(fdir1) # get class \n",
    "\n",
    "        # open file in memory, and parse as an image\n",
    "        myfile = zfile.open(name)\n",
    "        #img = matplotlib.image.imread(myfile)\n",
    "        img = skimage.io.imread(myfile)\n",
    "        img2 = skimage.transform.resize(img, (224,224), anti_aliasing=False)\n",
    "        \n",
    "        myfile.close()\n",
    "\n",
    "        imgdata.append(img2)\n",
    "        classes.append(fclass)\n",
    "        \n",
    "zfile.close()\n",
    "print(len(imgdata))\n",
    "print(img.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is a 224x224. There are 8 classes of differerent cakes.  Run the below code to show examples of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T02:51:33.626706Z",
     "start_time": "2023-01-24T02:51:33.382561Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,5))\n",
    "for i in range(8):\n",
    "    plt.subplot(2,4,i+1)\n",
    "    ind = i*100\n",
    "    plt.imshow(imgdata[ind])    \n",
    "    plt.title(classes[ind])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, store the images into a Tensor. ResNet assumes the data is [0,255] range, so we need to scale the images that were read in with skimage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T02:51:33.765318Z",
     "start_time": "2023-01-24T02:51:33.627864Z"
    }
   },
   "outputs": [],
   "source": [
    "Xraw = zeros((len(imgdata), 224, 224, 3))\n",
    "for i,img in enumerate(imgdata):\n",
    "    x = image.img_to_array(img)*255   # preprocessing expects range [0,255]\n",
    "    x = expand_dims(x, axis=0)\n",
    "    Xraw[i,:] = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we convert the class label strings into class numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T02:51:33.769470Z",
     "start_time": "2023-01-24T02:51:33.766271Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert class strings into integers\n",
    "print(\"class labels (strings):\", unique(classes))\n",
    "le = preprocessing.LabelEncoder()\n",
    "Y = le.fit_transform(classes)\n",
    "print(\"Converted labels:\")\n",
    "print(Y)\n",
    "Yb = keras.utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Deep features\n",
    "Now preprocess the images in imdata and put them into a 4D tensor for ResNet.  Store it in a tensor `Xim`.  \n",
    "Note that `preprocess_input` will overwrite its input data, so you may need to make a `copy` if you want to preserve `Xraw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T02:51:33.771693Z",
     "start_time": "2023-01-24T02:51:33.770174Z"
    }
   },
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features from Resnet50, call it `Xf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T02:51:33.929205Z",
     "start_time": "2023-01-24T02:51:33.927614Z"
    }
   },
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Train a classifier\n",
    "Split the data into training and testing for the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T02:51:37.437324Z",
     "start_time": "2023-01-24T02:51:37.215854Z"
    }
   },
   "outputs": [],
   "source": [
    "# randomly split data into train and test set\n",
    "( trainXf, testXf,       # features \n",
    "  trainY, testY,         # class labels\n",
    "  trainYb, testYb,       # class one-hot vectors\n",
    "  trainXim, testXim,     # processed images\n",
    "  trainimgdata, testimgdata,     # raw images\n",
    ") = \\\n",
    "  model_selection.train_test_split(Xf, Y, Yb, Xim, imgdata,\n",
    "  train_size=0.8, test_size=0.2, random_state=4487)\n",
    "\n",
    "print(trainXf.shape)\n",
    "print(testXf.shape)\n",
    "\n",
    "# cleanup memory\n",
    "del trainimgdata, Xraw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train a few traditional classifier (e.g, SVM, logistic regression, random forest, etc.) and compute the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T02:51:37.440513Z",
     "start_time": "2023-01-24T02:51:37.438664Z"
    }
   },
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze results\n",
    "\n",
    "Run the below code to visualize the predictions on the test set.  `mypred` are the class predictions from your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T02:53:09.526297Z",
     "start_time": "2023-01-24T02:53:06.458449Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get the class labels\n",
    "predYcl = le.inverse_transform(mypred)\n",
    "testYcl = le.inverse_transform(testY)\n",
    "\n",
    "plt.figure(figsize=(10,50))\n",
    "px = 8\n",
    "py = int(ceil(len(predYcl)/5))\n",
    "for i in range(len(predYcl)):\n",
    "    plt.subplot(py,px,i+1)\n",
    "    mytitle = predYcl[i] + \"\\n(\" + testYcl[i] + \")\" \n",
    "    plt.imshow(testimgdata[i], interpolation='nearest')\n",
    "    plt.title(mytitle, size=8)\n",
    "    plt.gca().set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T02:53:09.644915Z",
     "start_time": "2023-01-24T02:53:09.527294Z"
    }
   },
   "outputs": [],
   "source": [
    "CM = metrics.confusion_matrix(testY, mypred)\n",
    "\n",
    "plt.imshow(CM, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = arange(len(le.classes_))\n",
    "plt.xticks(tick_marks, le.classes_, rotation=90)\n",
    "plt.yticks(tick_marks, le.classes_)\n",
    "plt.xlabel('prediction')\n",
    "plt.ylabel('true')\n",
    "for i in range(len(le.classes_)):\n",
    "    for j in range(len(le.classes_)):\n",
    "        plt.text(j,i,\"{}\".format(CM[i,j]), horizontalalignment='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_How does the classifier make errors?_\n",
    "- **INSERT YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning\n",
    "\n",
    "Try using a pre-trained network as the backbone for a new network. You can try some of the following:\n",
    "- training an MLP classifier using the 2048 features from ResNet.\n",
    "- using other networks (e.g., InceptionNet) to extract the features.\n",
    "  - remember to change the pre-processing step too.\n",
    "- using the a feature map (7x7x2048) and applying a small CNN.\n",
    "- fine-tuning the whole network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T02:53:09.647314Z",
     "start_time": "2023-01-24T02:53:09.645778Z"
    }
   },
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "For your best deep learning model, visualize the result and analyze the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T03:09:47.845167Z",
     "start_time": "2023-01-24T03:09:47.843805Z"
    }
   },
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Where you able to improve the accuracy using deep learning? Analyze the errors from your best model._\n",
    "- **INSERT YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py38tfm28]",
   "language": "python",
   "name": "conda-env-py38tfm28-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.1875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
