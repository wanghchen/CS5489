{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** \\_\\_\\_\\_\\_\n",
    "\n",
    "**EID:** \\_\\_\\_\\_\\_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS5489 - Tutorial 3\n",
    "## Gender Classification from Face Images\n",
    "\n",
    "In this tutorial you will train a classifier to predict whether a face image is male or female.\n",
    "\n",
    "First we need to initialize Python.  Run the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import IPython.core.display         \n",
    "import matplotlib_inline   # setup output image format\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "import os\n",
    "import zipfile\n",
    "import fnmatch\n",
    "random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and Pre-processing\n",
    "We first need to load the images.  Download `photos-bw.zip` and put it in the same directory as this ipynb file.  **Do not unzip the file.** Then run the following cell to load the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgdata = []\n",
    "genders = []\n",
    "\n",
    "# load the zip file\n",
    "filename = 'photos-bw.zip'\n",
    "zfile = zipfile.ZipFile(filename, 'r')\n",
    "\n",
    "for name in zfile.namelist():\n",
    "    # check file name matches\n",
    "    if fnmatch.fnmatch(name, \"photos-bw/*.png\"):\n",
    "        print(\"loading\", name)\n",
    "        # open file in memory, and parse as an image\n",
    "        myfile = zfile.open(name)\n",
    "        img = matplotlib.image.imread(myfile)\n",
    "        myfile.close()\n",
    "        \n",
    "        # append to data\n",
    "        imgdata.append(img)\n",
    "        genders.append( int(name[len(\"photos-bw/\")] == 'm') )  # 0 is female, 1 is male\n",
    "        \n",
    "zfile.close()\n",
    "imgsize = img.shape\n",
    "print(\"DONE: loaded {} images\".format(len(imgdata)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is a 45x40 array of pixel values.  Run the below code to show an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(img.shape)\n",
    "plt.imshow(img, cmap='gray', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below code to show all the images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# function to make an image montage\n",
    "def image_montage(X, imsize=None, maxw=10):\n",
    "    \"\"\"X can be a list of images, or a matrix of vectorized images.\n",
    "      Specify imsize when X is a matrix.\"\"\"\n",
    "    tmp = []\n",
    "    numimgs = len(X)\n",
    "    \n",
    "    # create a list of images (reshape if necessary)\n",
    "    for i in range(0,numimgs):\n",
    "        if imsize != None:\n",
    "            tmp.append(X[i].reshape(imsize))\n",
    "        else:\n",
    "            tmp.append(X[i])\n",
    "    \n",
    "    # add blanks\n",
    "    if (numimgs > maxw) and (mod(numimgs, maxw) > 0):\n",
    "        leftover = maxw - mod(numimgs, maxw)\n",
    "        meanimg = 0.5*(X[0].max()+X[0].min())\n",
    "        for i in range(0,leftover):\n",
    "            tmp.append(ones(tmp[0].shape)*meanimg)\n",
    "    \n",
    "    # make the montage\n",
    "    tmp2 = []\n",
    "    for i in range(0,len(tmp),maxw):\n",
    "        tmp2.append( hstack(tmp[i:i+maxw]) )\n",
    "    montimg = vstack(tmp2) \n",
    "    return montimg\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.imshow(image_montage(imgdata), cmap='gray', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is a 2d array, but the classifier algorithms work on 1d vectors. Run the following code to convert all the images into 1d vectors by flattening.  The result should be a matrix where each row is a flattened image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = empty((50, prod(imgdata[0].shape))) # create empty array\n",
    "for i,img in enumerate(imgdata):\n",
    "    X[i,:] = ravel(img)           # for each image, turn it into a vector\n",
    "Y = asarray(genders)  # convert list to numpy array\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will shift the pixel values so that gray is 0.0, black is -0.5 and white is 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before: min={}, max={}\".format(X.min(), X.max()))\n",
    "X -= 0.5\n",
    "print(\"After:  min={}, max={}\".format(X.min(), X.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, split the dataset into a training set and testing set. We select 80% for training and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly split data into 80% train and 20% test set\n",
    "trainX, testX, trainY, testY = \\\n",
    "  model_selection.train_test_split(X, Y, \n",
    "  train_size=0.80, test_size=0.20, random_state=4487)\n",
    "\n",
    "print(trainX.shape)\n",
    "print(testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the average image for later\n",
    "avgX = mean(X,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "Train a logistic regression classifier.  Use cross-validation to select the best C parameter.\n",
    "\n",
    "**NOTE:** If you are running on DeepDive server, the number of visible CPUs is 32, which is shared among all students. Please do not use `n_jobs=-1`!!  Instead use `n_jobs=4` or `n_jobs=8`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the learned model to predict the genders for the training and testing data. What is the accuracy on the training set? What is the accuracy on the testing set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the classifier\n",
    "Run the below code to show the hyperplane parameter $\\mathbf{w}$ as an image.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg is the learned logistic regression model\n",
    "wimg = logreg.coef_.reshape(imgsize)      # get the w and reshape into an image\n",
    "mycmap = matplotlib.colors.LinearSegmentedColormap.from_list('mycmap', [\"#0000FF\", \"#FFFFFF\", \"#FF0000\"])\n",
    "mm = max(wimg.max(), -wimg.min())\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('average image')\n",
    "plt.imshow(avgX.reshape(imgsize), cmap='gray')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(wimg, interpolation='nearest', cmap=mycmap, vmin=-mm, vmax=mm)\n",
    "plt.colorbar()\n",
    "plt.title(\"LR weight image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the classifier prediction is based on the sign of the function $f(\\mathbf{x}) = \\mathbf{w}^T\\mathbf{x}+b = \\sum_{i=1}^P w_ix_i + b$.  Here each $x_i$ is a pixel in the face image, and $w_i$ is the corresponding weight.  Hence, the function is multiplying face image by the weight image, and then summing over all pixels.\n",
    "\n",
    "In order for $f(\\mathbf{x})$ to be positive, then the positive values of the weight image (red regions) should match the positive values in the face image (white pixels), and the negative values of the weight image (blue regions) should be matched with negative values in the face image (black pixels).\n",
    "\n",
    "Hence, we can have the following interpretation:\n",
    "<table>\n",
    "<tr><th>Class</th><th>red regions (positive weights)</th><th>blue regions (negative weights)</th><th>white regions (weights near 0)</th></tr>\n",
    "<tr><td>+1 class (male)</td><td>white pixels in face image</td><td>black pixels in face image</td><td>region not important</td></tr>\n",
    "<tr><td>-1 class (female)</td><td>black pixels in face image</td><td>white pixels in face image</td><td>region not important</td></tr>\n",
    "</table>\n",
    "  \n",
    "_Looking at the weight image, what parts of the face image is the classifier looking at to determine the gender?  Does it make sense?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **INSERT YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the misclassified faces in the test set.  Run the below code to show the misclassifed and correctly classified faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# predYtest are the class predictions on the test set.\n",
    "\n",
    "# find misclassified test images\n",
    "inds = where(predYtest != testY) # get indices of misclassified test images\n",
    "# make a montage\n",
    "badimgs = image_montage(testX[inds], imsize=imgsize)\n",
    "\n",
    "# find correctly classified test images\n",
    "inds = where(predYtest == testY)\n",
    "goodimgs = image_montage(testX[inds], imsize=imgsize)\n",
    "    \n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(badimgs, cmap='gray', interpolation='nearest')\n",
    "plt.title('misclassified faces')\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(goodimgs, cmap='gray', interpolation='nearest')\n",
    "plt.title('correctly classified faces')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Why did the classifier make incorrect predictions on the misclassified faces?_\n",
    "- **INSERT YOUR ANSWER HERE**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine\n",
    "Now train a support vector machine (SVM) on the same training and testing data.  Use cross-validation to select the best $C$ parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the training and test accuracy for the SVM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to before, plot an image of the hyperplane parameters $w$, and view the misclassified and correctly classified test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Are there any differences between the $w$ for logistic regressiona and the $w$ for SVM?  Is there any interpretation for the differences?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **INSERT YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying cropped faces\n",
    "It seems that the hair around the face and forehead are discriminative enough to perform gender classifixation. Now try to perform the same task but only focusing on the face image, and not the hair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a mask over the face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgmask = full((img.shape), False)\n",
    "#imgmask[17:41,8:32] = True\n",
    "#masksize = (24,24)\n",
    "imgmask[18:40,11:29] = True\n",
    "masksize = (22,18)\n",
    "plt.imshow(imgmask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we crop out the face image to create the new inputs.  The vectors are now 576-dim, and corresponding images are 24x24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xm = X[:,imgmask.ravel()]\n",
    "Xm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the cropped images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_montage(Xm, imsize=masksize), cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the same training/test split as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly split data into 80% train and 20% test set\n",
    "trainXm, testXm, trainY, testY = \\\n",
    "  model_selection.train_test_split(Xm, Y, \n",
    "  train_size=0.80, test_size=0.20, random_state=4487)\n",
    "\n",
    "print(trainXm.shape)\n",
    "print(testXm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgXm = avgX[imgmask.ravel()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train logistic regression and SVM classifiers on the new cropped images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the train/test accuracies of the two classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the classification performance? Which performs better and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **INSERT YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the weights as an image and interpret what discriminative information each classifier is using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **INSERT YOUR ANSWER HERE**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
